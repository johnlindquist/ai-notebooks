{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AestheticSorter\n",
    "\n",
    "This notebook lets you sort a folder of images by aesthetic rating. You can choose from a few pretrained aesthetic models.\n",
    "* laion_aesthetic by [LAION](https://x.com/laion_ai)\n",
    "* laion_aesthetic_improved by [christophschuhmann](https://github.com/christophschuhmann)\n",
    "* aesthetika by [pharmapsychotic](https://x.com/pharmapsychotic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SHXr202DoPU0",
    "outputId": "01887fe1-972a-4d1a-db14-04766d32e2e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: Tesla T4 (UUID: GPU-f5156b3d-9a0c-ecbf-01bb-1cf4de9307e9)\n"
     ]
    }
   ],
   "source": [
    "#@title Check GPU\n",
    "!nvidia-smi -L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4B0zTjLkoPU1",
    "outputId": "9a6ee21e-23c2-426c-e9c8-93b14536ab85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "#@title Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "te45Ok7-oPU1"
   },
   "outputs": [],
   "source": [
    "#@title Install dependencies\n",
    "!pip install requests safetensors tqdm\n",
    "!pip install git+https://github.com/openai/CLIP.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellView": "form",
    "id": "S9ECvqR4oPU2"
   },
   "outputs": [],
   "source": [
    "#@title Code definitions\n",
    "import hashlib\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "\n",
    "import clip\n",
    "import requests\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from safetensors import safe_open\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "clip_model, preprocess = None, None\n",
    "\n",
    "class BaseAestheticPredictor(nn.Module):\n",
    "    URL: str\n",
    "    HASH: Optional[str] = None\n",
    "\n",
    "    def __init__(self, cache_dir: str = \".cache\"):\n",
    "        super().__init__()\n",
    "        self.cache_dir = Path(cache_dir)\n",
    "        self.cache_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    def _download_if_needed(self) -> Path:\n",
    "        url_path = self.URL.split(\"?\")[0]  # remove query params\n",
    "        fname = self.cache_dir / Path(url_path).name.replace(\"+\", \"_\")\n",
    "\n",
    "        if not fname.exists():\n",
    "            response = requests.get(self.URL, stream=True)\n",
    "            response.raise_for_status()\n",
    "\n",
    "            with open(fname, \"wb\") as f:\n",
    "                for chunk in response.iter_content(chunk_size=8192):\n",
    "                    f.write(chunk)\n",
    "\n",
    "        # verify hash\n",
    "        with open(fname, \"rb\") as f:\n",
    "            file_hash = hashlib.sha256(f.read()).hexdigest()\n",
    "        if file_hash != self.HASH:\n",
    "            fname.unlink()\n",
    "            raise ValueError(f\"hash verification failed for {fname}\")\n",
    "\n",
    "        return fname\n",
    "\n",
    "class Aesthetika(BaseAestheticPredictor):\n",
    "    URL = \"https://pharmapsychotic.com/models/aesthetika_20240424.safetensors\"\n",
    "    HASH = \"fad60cfdfb7857c22c8f1c99c05b463f5aded3766124bf92aa21b7633c035982\"\n",
    "\n",
    "    def __init__(self, cache_dir: str = \".cache\"):\n",
    "        super().__init__(cache_dir)\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(768, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Identity(),\n",
    "            nn.Linear(1024, 1),\n",
    "        )\n",
    "        state_dict = {}\n",
    "        model_path = self._download_if_needed()\n",
    "        with safe_open(model_path, framework=\"pt\", device=\"cpu\") as f:\n",
    "            for key in f.keys():\n",
    "                state_dict[key] = f.get_tensor(key)\n",
    "        self.load_state_dict(state_dict)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.layers(x)\n",
    "\n",
    "class LaionAesthetic(BaseAestheticPredictor):\n",
    "    URL = \"https://github.com/LAION-AI/aesthetic-predictor/blob/main/sa_0_4_vit_l_14_linear.pth?raw=true\"\n",
    "    HASH = \"2cd4e60f4f24ae3bcd57b847b13c1f3ba27edc28cc1a7f9ce74ee9f421243cba\"\n",
    "\n",
    "    def __init__(self, cache_dir: str = \".cache\"):\n",
    "        super().__init__(cache_dir)\n",
    "        self.layers = nn.Sequential(nn.Linear(768, 1))\n",
    "        weights = torch.load(self._download_if_needed(), weights_only=True)\n",
    "        weights = {f\"layers.0.{k}\": v for k, v in weights.items()}\n",
    "        self.load_state_dict(weights)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.layers(x)\n",
    "\n",
    "class LaionAestheticImproved(BaseAestheticPredictor):\n",
    "    URL = \"https://github.com/christophschuhmann/improved-aesthetic-predictor/blob/main/sac+logos+ava1-l14-linearMSE.pth?raw=true\"\n",
    "    HASH = \"21dd590f3ccdc646f0d53120778b296013b096a035a2718c9cb0d511bff0f1e0\"\n",
    "\n",
    "    def __init__(self, cache_dir: str = \".cache\"):\n",
    "        super().__init__(cache_dir)\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(768, 1024),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(1024, 128),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(64, 16),\n",
    "            nn.Linear(16, 1)\n",
    "        )\n",
    "        weights = torch.load(self._download_if_needed(), weights_only=True)\n",
    "        self.load_state_dict(weights)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.layers(x)\n",
    "\n",
    "def create_model(name: str, **kwargs) -> BaseAestheticPredictor:\n",
    "    models = {\n",
    "        \"aesthetika\": Aesthetika,\n",
    "        \"laion_aesthetic\": LaionAesthetic,\n",
    "        \"laion_aesthetic_improved\": LaionAestheticImproved\n",
    "    }\n",
    "    if name not in models:\n",
    "        raise ValueError(f\"Invalid model {name}\")\n",
    "    return models[name](**kwargs)\n",
    "\n",
    "def predict_rating(model, image_path):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    image = preprocess(image).unsqueeze(0).to(device)\n",
    "    with torch.inference_mode():\n",
    "        image_embed = clip_model.encode_image(image)\n",
    "        aesthetic_rating = model(image_embed.float())\n",
    "    return aesthetic_rating.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5cadyc4soPU2",
    "outputId": "5a909a3b-2e71-4ac1-a36d-7b8e52818e9f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating aesthetic ratings: 100%|██████████| 8/8 [00:00<00:00, 12.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving in sorted order to /content/gdrive/MyDrive/my_images/sorted...\n",
      "Sorted order:\n",
      "['0004', '0005', '0003', '0008', '0006', '0007', '0009', '0002']\n"
     ]
    }
   ],
   "source": [
    "#@title Let's sort!\n",
    "#@markdown Click Files folder on left then right click a folder and choose\n",
    "#@markdown \"Copy path\" and paste that into `images_folder`. You can choose an\n",
    "#@markdown existing path in your Google Drive or upload to a new folder.\n",
    "#@markdown <br><br>\n",
    "\n",
    "images_folder = \"/content/gdrive/MyDrive/my_images\" #@param {type:\"string\"}\n",
    "sorted_folder = \"/content/gdrive/MyDrive/my_images/sorted\" #@param {type:\"string\"}\n",
    "aesthetic_model = 'laion_aesthetic_improved' #@param ['aesthetika', 'laion_aesthetic', 'laion_aesthetic_improved']\n",
    "\n",
    "files = [file for file in os.listdir(images_folder) if os.path.splitext(file)[1] in ('.png', '.jpg', '.jpeg', '.webp')]\n",
    "if not len(files):\n",
    "    raise Exception(f\"No image files found in {images_folder}\")\n",
    "\n",
    "if clip_model is None:\n",
    "    print(\"Loading CLIP model...\")\n",
    "    clip_model, preprocess = clip.load(\"ViT-L/14\", device=device)\n",
    "\n",
    "# calculate aesthetic ratings for all images\n",
    "model = create_model(aesthetic_model)\n",
    "model.eval()\n",
    "model.to(device)\n",
    "ratings = []\n",
    "for file in tqdm(files, desc=\"Calculating aesthetic ratings\"):\n",
    "    rating = predict_rating(model, os.path.join(images_folder, file))\n",
    "    ratings.append(rating)\n",
    "\n",
    "# sort by aesthetic rating\n",
    "ordering = sorted(range(len(ratings)), key=lambda i: ratings[i], reverse=True)\n",
    "\n",
    "print(f\"Saving in sorted order to {sorted_folder}...\")\n",
    "if not os.path.exists(sorted_folder):\n",
    "    os.makedirs(sorted_folder)\n",
    "for i in range(len(files)):\n",
    "    file = files[ordering[i]]\n",
    "    rating = ratings[ordering[i]]\n",
    "    base, ext = os.path.splitext(file)\n",
    "    dest = os.path.join(sorted_folder, f\"{i:04d}_{rating:.2f}_{base}.{ext}\")\n",
    "    if os.path.exists(dest):\n",
    "        os.remove(dest)\n",
    "    shutil.copyfile(os.path.join(images_folder, file), dest)\n",
    "\n",
    "print(\"Sorted order:\")\n",
    "print([os.path.splitext(files[ordering[i]])[0] for i in range(len(ordering))])\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
